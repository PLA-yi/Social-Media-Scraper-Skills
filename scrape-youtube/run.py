#!/usr/bin/env python3
"""YouTube çˆ¬å– â€” è°ƒç”¨æœ¬åœ° scraper æœåŠ¡ API"""

import argparse
import json
import sys
import urllib.request

SERVER = "http://localhost:8000"


def check_server():
    try:
        urllib.request.urlopen(SERVER, timeout=3)
        return True
    except Exception:
        return False


def main():
    parser = argparse.ArgumentParser(description="YouTube çˆ¬å–")
    parser.add_argument("--target", required=True, help="æœç´¢å…³é”®è¯æˆ–é¢‘é“é“¾æ¥")
    parser.add_argument("--mode", choices=["keyword", "blogger"], default="keyword",
                        help="keyword=å…³é”®è¯æœç´¢  blogger=é¢‘é“é‡‡é›†")
    parser.add_argument("--count", type=int, default=10, help="é‡‡é›†è§†é¢‘æ•°é‡")
    args = parser.parse_args()

    if not check_server():
        print("âŒ æœåŠ¡æœªå¯åŠ¨ï¼Œè¯·å…ˆåœ¨é¡¹ç›®ç›®å½•æ‰§è¡Œï¼špython3 server.py")
        sys.exit(1)

    print(f"â–¶ YouTube çˆ¬å–")
    print(f"  ç›®æ ‡ï¼š{args.target}  æ¨¡å¼ï¼š{args.mode}  æ•°é‡ï¼š{args.count}")

    payload = json.dumps({
        "platform": "youtube",
        "target": args.target,
        "mode": args.mode,
        "count": args.count,
    }).encode()

    req = urllib.request.Request(
        f"{SERVER}/api/scrape",
        data=payload,
        headers={"Content-Type": "application/json"},
        method="POST",
    )
    with urllib.request.urlopen(req, timeout=10) as resp:
        result = json.loads(resp.read())

    print(f"âœ… ä»»åŠ¡å·²æäº¤ï¼š{result}")
    print(f"ğŸ“‹ å®æ—¶æ—¥å¿—ï¼š{SERVER}")


if __name__ == "__main__":
    main()
